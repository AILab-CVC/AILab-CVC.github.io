<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style data-merge-styles="true"></style><style data-merge-styles="true"></style><style data-merge-styles="true"></style>

<title>Computer Vision Center (CVC), Tencent AI Lab</title>
<style type="text/css">
body{
  /* font-family: cambria, calibri, garamond, century, gulim, dotum, arial; */
  font-family: 'Lato', arial, sans-serif;
  font-size:16px;
  margin: 10 auto;
  width:90%;
  min-width:200px;
  max-width:1200px;
  line-height: 150%;
  width:expression_r(Math.max(200, Math.min(1200, document.body.offsetWidth-40))+"px");
}
</style>

<style>
table {
/* font-family: cambria, calibri, garamond, century, gulim, dotum, arial; */
font-family: 'Lato', arial, sans-serif;
border-collapse: collapse;
width: 100%;
font-size:16px;
}

</style>

</head>
<body data-new-gr-c-s-check-loaded="14.1130.0" data-gr-ext-installed="">


<table class="wsite-multicol-table">
<tbody class="wsite-multicol-tbody">
<tr class="wsite-multicol-tr">

<td class="wsite-multicol-col">
<img border="0" height="100" width="100" src="https://avatars.githubusercontent.com/u/132903285" align="left">
</td>

<td style="width:10pt"></td>

<td align="left">
<p align="right">  <a href="https://ai.tencent.com/ailab/en/index">Tencent AI Lab HomePage</a> </p>
<h2>Computer Vision Center (CVC), Tencent AI Lab</h2>

<p>Tencent AILab CVC research group focuses on 1) vision and multimodal foudation models; 2)visual content generaiton; 3) 3D digitization/generation, immersive content creation and 4) semantic digital human. You can see more our projects on <a href="https://github.com/AILab-CVC">our GitHub</a>.</p>
<br><br>
</p>
</td>

</tr>
</tbody>
</table>


<p></p>



<h2>News</h2>

<p></p>

<ul style="line-height:1.2">
<li type="disc">Oct 2023: Release <a href="https://github.com/AILab-CVC/SEED">SEED-LLaMA</a>, featuring multi-turn in-context emergent capabilities.</li>
<li type="disc">Sep 2023: Three papers are accepted to NeurIPS 2023.</li>
<li type="disc">Sep 2023: Three papers are accepted to SIGGRAPH Asia 2023.</li>
</ul>

<p></p>




<!-- <h2>Research Directions</h2>

<p></p>

<ul style="line-height:1.5">
  <li type="disc"><b>Vision and multimodal foudation models</b>:

  </li>

</ul> -->




<h2>Selected Publications</h2>

<ul style="line-height:1.2">
<li type="disc"><b>Inserting Anybody in Diffusion Models via Celeb Basis.</b> <i>Ge Yuan, Xiaodong Cun, Yong Zhang, Maomao Li, Chenyang Qi, Xintao Wang, Ying Shan, Huicheng Zheng.</i> NeurIPS 2023.</li>
<li type="disc"><b>GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction.</b> <i>Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, Ying Shan.</i> NeurIPS 2023.</li>
<li type="disc"><b>Meta-Adapter: An Online Few-shot Learner for Vision-Language Model.</b> <i>Cheng Cheng, Lin Song, Ruoyi Xue, Hang Wang, Hongbin Sun, Yixiao Ge, Ying Shan.</i> NeurIPS 2023.</li>
<li type="disc"><b>Neural Point-based Volumetric Avatar.</b> <i>Cong Wang, Di Kang, Yanpei Cao, Linchao Bao, Ying Shan, Song-Hai Zhang.</i> SIGGRAPH Asia 2023.</li>
<li type="disc"><b>Local Implicit Ray Function for Generalizable Radiance Field Representation.</b> <i>Xin Huang, Qi Zhang, Ying Feng, Xiaoyu Li, Xuan Wang, Qing Wang.</i> SIGGRAPH Asia 2023.</li>
<li type="disc"><b>TaleCrafter: Interactive Story Visualization with Multiple Characters.</b> <i>Yuan Gong, Youxin Pang, Xiaodong Cun, Menghan Xia, Yingqing He, Haoxin Chen, Longyue Wang, Yong Zhang, Xintao Wang, Ying Shan, Yujiu Yang.</i> SIGGRAPH Asia 2023.</li>
</ul>